#!/usr/bin/env python3
"""
SS-UIE æ°´ä¸‹å›¾åƒå¢å¼ºæµ‹è¯•è„šæœ¬
å°†Jupyter notebookè½¬æ¢ä¸ºå¯æ‰§è¡Œçš„Pythonè„šæœ¬

ä½¿ç”¨æ–¹æ³•:
python test_ss_uie.py --input_dir ./data/Test_400/input --output_dir ./data/Test_400/output --model_path ./saved_models/SS_UIE.pth

è¦æ±‚:
- ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–åŒ…ï¼ˆç‰¹åˆ«æ˜¯mamba_ssmï¼‰
- æœ‰å¯ç”¨çš„GPUå’ŒCUDAç¯å¢ƒ
- æ¨¡å‹æƒé‡æ–‡ä»¶å­˜åœ¨
"""

import argparse
import os
import sys
import time
from pathlib import Path

import cv2
from torchvision.utils import save_image

# å°è¯•å¯¼å…¥æ‰€æœ‰ä¾èµ–
try:
    import pytorch_ssim

    PYTORCH_SSIM_AVAILABLE = True
except ImportError:
    PYTORCH_SSIM_AVAILABLE = False

try:
    import mamba_ssm

    MAMBA_SSM_AVAILABLE = True
except ImportError:
    MAMBA_SSM_AVAILABLE = False

try:
    from net.model import SS_UIE_model

    MODEL_AVAILABLE = True
except ImportError:
    MODEL_AVAILABLE = False

try:
    from utils.utils import *
    from utils.LAB import *
    from utils.LCH import *
    from utils.FDL import *

    UTILS_AVAILABLE = True
except ImportError:
    UTILS_AVAILABLE = False


def check_dependencies():
    """æ£€æŸ¥å¿…è¦çš„ä¾èµ–åŒ…"""
    missing_deps = []

    if not PYTORCH_SSIM_AVAILABLE:
        missing_deps.append("pytorch_ssim")

    if not MAMBA_SSM_AVAILABLE:
        missing_deps.append("mamba_ssm")

    if not MODEL_AVAILABLE:
        missing_deps.append("SS_UIE_model (æ£€æŸ¥net/model.pyæ˜¯å¦å­˜åœ¨)")

    if not UTILS_AVAILABLE:
        missing_deps.append("utils modules (æ£€æŸ¥utilsæ–‡ä»¶å¤¹)")

    if missing_deps:
        print("âŒ ç¼ºå°‘ä»¥ä¸‹ä¾èµ–:")
        for dep in missing_deps:
            print(f"   - {dep}")
        print("\nè¯·å…ˆå®‰è£…ç¼ºå¤±çš„ä¾èµ–åŒ…")
        return False

    print("âœ… æ‰€æœ‰ä¾èµ–æ£€æŸ¥é€šè¿‡")
    return True


def setup_device():
    """è®¾ç½®GPUè®¾å¤‡"""
    if not torch.cuda.is_available():
        print("âŒ CUDAä¸å¯ç”¨ï¼Œè¯·ç¡®ä¿å®‰è£…äº†GPUç‰ˆæœ¬çš„PyTorch")
        return None

    device = torch.device('cuda:0')
    torch.cuda.set_device(0)
    torch.set_default_tensor_type(torch.FloatTensor)

    print(f"âœ… ä½¿ç”¨è®¾å¤‡: {device}")
    print(f"   GPUåç§°: {torch.cuda.get_device_name(0)}")
    print(f"   æ˜¾å­˜å®¹é‡: {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.1f} GB")

    return device


def load_model(model_path, device):
    """åŠ è½½SS-UIEæ¨¡å‹"""
    try:
        if not MODEL_AVAILABLE:
            raise ImportError("SS_UIE_model ä¸å¯ç”¨")

        print("ğŸ”„ æ­£åœ¨åŠ è½½æ¨¡å‹...")

        # åˆå§‹åŒ–æ¨¡å‹
        model = SS_UIE_model(in_channels=3, channels=16, num_resblock=4, num_memblock=4)
        model = model.to(device)

        # ä½¿ç”¨DataParallelï¼ˆå¦‚æœæœ‰å¤šä¸ªGPUï¼‰
        if torch.cuda.device_count() > 1:
            model = nn.DataParallel(model)
            print(f"   ä½¿ç”¨ {torch.cuda.device_count()} ä¸ªGPU")

        # åŠ è½½é¢„è®­ç»ƒæƒé‡
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")

        checkpoint = torch.load(model_path, map_location=device)
        model.load_state_dict(checkpoint)
        model.eval()

        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
        return model

    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None


def preprocess_image(image_path, target_size=(256, 256)):
    """é¢„å¤„ç†è¾“å…¥å›¾åƒ"""
    try:
        # è¯»å–å›¾åƒ
        img = cv2.imread(image_path)
        if img is None:
            raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {image_path}")

        # è°ƒæ•´å¤§å°
        img = cv2.resize(img, target_size)

        # BGRè½¬RGB
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # è½¬æ¢ä¸ºtensor
        img = np.array(img).astype(np.float32)
        img = torch.from_numpy(img)
        img = img.permute(2, 0, 1).unsqueeze(0)  # [1, 3, H, W]
        img = img / 255.0  # å½’ä¸€åŒ–åˆ°[0,1]

        return img

    except Exception as e:
        print(f"âŒ å›¾åƒé¢„å¤„ç†å¤±è´¥ {image_path}: {e}")
        return None


def process_single_image(model, image_path, output_path, device):
    """å¤„ç†å•å¼ å›¾åƒ"""
    try:
        # é¢„å¤„ç†
        input_tensor = preprocess_image(image_path)
        if input_tensor is None:
            return False

        input_tensor = input_tensor.to(device)

        # æ¨ç†
        with torch.no_grad():
            output = model(input_tensor)

        # ä¿å­˜ç»“æœ
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        save_image(output, output_path, nrow=1, normalize=True)

        return True

    except Exception as e:
        print(f"âŒ å¤„ç†å›¾åƒå¤±è´¥ {image_path}: {e}")
        return False


def main():
    parser = argparse.ArgumentParser(description='SS-UIE æ°´ä¸‹å›¾åƒå¢å¼ºæµ‹è¯•')
    parser.add_argument('--input_dir', type=str, default='./data/Test_400/input/',
                        help='è¾“å…¥å›¾åƒæ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./data/Test_400/output/',
                        help='è¾“å‡ºå›¾åƒæ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--model_path', type=str, default='./saved_models/SS_UIE.pth',
                        help='æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--image_size', type=int, default=256,
                        help='è¾“å…¥å›¾åƒå°ºå¯¸ (é»˜è®¤: 256x256)')
    parser.add_argument('--batch_process', action='store_true',
                        help='æ‰¹é‡å¤„ç†æ¨¡å¼')

    args = parser.parse_args()

    print("ğŸš€ SS-UIE æ°´ä¸‹å›¾åƒå¢å¼ºæµ‹è¯•è„šæœ¬")
    print("=" * 50)

    # æ£€æŸ¥ä¾èµ–
    if not check_dependencies():
        sys.exit(1)

    # è®¾ç½®è®¾å¤‡
    device = setup_device()
    if device is None:
        sys.exit(1)

    # åŠ è½½æ¨¡å‹
    model = load_model(args.model_path, device)
    if model is None:
        sys.exit(1)

    # æ£€æŸ¥è¾“å…¥ç›®å½•
    if not os.path.exists(args.input_dir):
        print(f"âŒ è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {args.input_dir}")
        sys.exit(1)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)

    # è·å–å›¾åƒåˆ—è¡¨
    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.tiff']
    image_files = []

    for ext in image_extensions:
        image_files.extend(Path(args.input_dir).glob(f'*{ext}'))
        image_files.extend(Path(args.input_dir).glob(f'*{ext.upper()}'))

    if not image_files:
        print(f"âŒ åœ¨ {args.input_dir} ä¸­æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶")
        sys.exit(1)

    # æŒ‰æ–‡ä»¶åæ’åº
    image_files.sort(key=lambda x: int(x.stem) if x.stem.isdigit() else x.stem)

    print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} å¼ å›¾åƒ")
    print(f"ğŸ“¤ è¾“å‡ºç›®å½•: {args.output_dir}")
    print("=" * 50)

    # å¤„ç†å›¾åƒ
    start_time = time.time()
    success_count = 0

    for i, image_file in enumerate(image_files, 1):
        print(f"ğŸ”„ [{i}/{len(image_files)}] å¤„ç†: {image_file.name}")

        output_path = os.path.join(args.output_dir, image_file.name)

        if process_single_image(model, str(image_file), output_path, device):
            success_count += 1
            print(f"âœ… å®Œæˆ: {output_path}")
        else:
            print(f"âŒ å¤±è´¥: {image_file.name}")

    # ç»Ÿè®¡ç»“æœ
    total_time = time.time() - start_time
    print("=" * 50)
    print(f"âœ… å¤„ç†å®Œæˆ!")
    print(f"   æˆåŠŸ: {success_count}/{len(image_files)} å¼ å›¾åƒ")
    print(f"   ç”¨æ—¶: {total_time:.2f} ç§’")
    print(f"   å¹³å‡: {total_time / len(image_files):.2f} ç§’/å¼ ")

    if success_count < len(image_files):
        print(f"âš ï¸  æœ‰ {len(image_files) - success_count} å¼ å›¾åƒå¤„ç†å¤±è´¥")


if __name__ == "__main__":
    main()
