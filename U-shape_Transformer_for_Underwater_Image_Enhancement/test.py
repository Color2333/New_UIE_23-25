#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
U-shape Transformer for Underwater Image Enhancement - æµ‹è¯•è„šæœ¬
è½¬æ¢è‡ª test.ipynb
"""

import argparse

import cv2
from torch.autograd import Variable
from torchvision.utils import save_image

from loss.LCH import *
# å¯¼å…¥ç½‘ç»œå’Œå·¥å…·
from net.Ushape_Trans import *
from net.utils import *


def split(img):
    """åˆ†å‰²å›¾åƒä¸ºä¸åŒå°ºåº¦"""
    output = []
    output.append(F.interpolate(img, scale_factor=0.125))
    output.append(F.interpolate(img, scale_factor=0.25))
    output.append(F.interpolate(img, scale_factor=0.5))
    output.append(img)
    return output


def compute_psnr(img1, img2):
    """è®¡ç®—PSNRå€¼"""
    mse = np.mean((img1 / 255. - img2 / 255.) ** 2)
    if mse < 1.0e-10:
        return 100
    PIXEL_MAX = 1
    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))


def compute_mse(img1, img2):
    """è®¡ç®—MSEå€¼"""
    mse = np.mean((img1 / 255. - img2 / 255.) ** 2)
    return mse


def setup_environment():
    """è®¾ç½®è¿è¡Œç¯å¢ƒ"""
    os.environ["KMP_DUPLICATE_LIB_OK"] = "TRUE"
    os.environ["CUDA_VISIBLE_DEVICES"] = '0'
    torch.set_default_dtype(torch.float32)


def load_generator(model_path, device='cuda'):
    """åŠ è½½ç”Ÿæˆå™¨æ¨¡å‹"""
    print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")

    # åˆå§‹åŒ–ç”Ÿæˆå™¨
    generator = Generator().to(device)

    # åŠ è½½æ¨¡å‹æƒé‡
    try:
        generator.load_state_dict(torch.load(model_path, weights_only=True, map_location=device))
        print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"å®‰å…¨åŠ è½½å¤±è´¥: {e}")
        print("å°è¯•ä¼ ç»Ÿæ–¹å¼åŠ è½½...")
        generator.load_state_dict(torch.load(model_path, weights_only=False, map_location=device))
        print("âœ… ä¼ ç»Ÿæ–¹å¼åŠ è½½æˆåŠŸ")

    # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    generator.eval()
    return generator


def process_image(img_path, generator, device='cuda', target_size=(256, 256)):
    """å¤„ç†å•å¼ å›¾åƒ"""
    # è¯»å–å¹¶é¢„å¤„ç†å›¾åƒ
    imgx = cv2.imread(img_path)
    if imgx is None:
        raise ValueError(f"æ— æ³•è¯»å–å›¾åƒ: {img_path}")

    imgx = cv2.resize(imgx, target_size)
    imgx = cv2.cvtColor(imgx, cv2.COLOR_BGR2RGB)
    imgx = np.array(imgx).astype('float32')

    # è½¬æ¢ä¸ºå¼ é‡
    imgx = torch.from_numpy(imgx)
    imgx = imgx.permute(2, 0, 1).unsqueeze(0)
    imgx = imgx / 255.0
    imgx = Variable(imgx).to(device)

    # æ¨¡å‹æ¨ç†
    with torch.no_grad():
        output = generator(imgx)

    return output[3].data


def test_images(input_dir, output_dir, model_path, device='cuda'):
    """æµ‹è¯•æ‰€æœ‰å›¾åƒ"""
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    print(f"âœ… è¾“å‡ºç›®å½•å·²åˆ›å»º: {output_dir}")

    # åŠ è½½æ¨¡å‹
    generator = load_generator(model_path, device)

    # è·å–å›¾åƒåˆ—è¡¨
    if not os.path.exists(input_dir):
        raise ValueError(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")

    path_list = os.listdir(input_dir)
    path_list.sort(key=lambda x: int(x.split('.')[0]) if x.split('.')[0].isdigit() else 0)

    print(f"æ‰¾åˆ° {len(path_list)} å¼ å›¾åƒ")

    # å¤„ç†æ¯å¼ å›¾åƒ
    for i, item in enumerate(path_list, 1):
        try:
            print(f"å¤„ç†ç¬¬ {i}/{len(path_list)} å¼ å›¾åƒ: {item}")

            img_path = os.path.join(input_dir, item)
            output_tensor = process_image(img_path, generator, device)

            # ä¿å­˜ç»“æœ
            output_path = os.path.join(output_dir, item)
            save_image(output_tensor, output_path, nrow=5, normalize=True)
            print(f"âœ… ä¿å­˜æˆåŠŸ: {output_path}")

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥ {item}: {e}")

    print(f"ğŸ‰ å›¾åƒå¤„ç†å®Œæˆï¼å…±å¤„ç† {len(path_list)} å¼ å›¾åƒ")


def evaluate_results(gt_dir, output_dir):
    """è¯„ä¼°ç»“æœè´¨é‡"""
    if not os.path.exists(gt_dir):
        print("âš ï¸ æœªæ‰¾åˆ°çœŸå€¼å›¾åƒç›®å½•ï¼Œè·³è¿‡è¯„ä¼°")
        return

    if not os.path.exists(output_dir):
        print("âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œæ— æ³•è¯„ä¼°")
        return

    path_list = os.listdir(gt_dir)
    path_list.sort(key=lambda x: int(x.split('.')[0]) if x.split('.')[0].isdigit() else 0)

    PSNR = []

    print("å¼€å§‹è¯„ä¼°ç»“æœè´¨é‡...")

    for item in path_list:
        gt_path = os.path.join(gt_dir, item)
        output_path = os.path.join(output_dir, item)

        if not os.path.exists(output_path):
            print(f"âš ï¸ è¾“å‡ºå›¾åƒä¸å­˜åœ¨: {output_path}")
            continue

        try:
            # è¯»å–å›¾åƒ
            imgx = cv2.imread(gt_path)
            imgy = cv2.imread(output_path)

            if imgx is None or imgy is None:
                print(f"âš ï¸ æ— æ³•è¯»å–å›¾åƒ: {item}")
                continue

            # è°ƒæ•´å°ºå¯¸
            imgx = cv2.resize(imgx, (256, 256))
            imgy = cv2.resize(imgy, (256, 256))

            # è®¡ç®—PSNR
            psnr1 = compute_psnr(imgx[:, :, 0], imgy[:, :, 0])
            psnr2 = compute_psnr(imgx[:, :, 1], imgy[:, :, 1])
            psnr3 = compute_psnr(imgx[:, :, 2], imgy[:, :, 2])

            psnr = (psnr1 + psnr2 + psnr3) / 3.0
            PSNR.append(psnr)

        except Exception as e:
            print(f"âŒ è¯„ä¼°å¤±è´¥ {item}: {e}")

    if PSNR:
        PSNR = np.array(PSNR)
        mean_psnr = PSNR.mean()
        print(f"ğŸ“Š å¹³å‡PSNR: {mean_psnr:.2f} dB")
        print(f"ğŸ“Š PSNRèŒƒå›´: {PSNR.min():.2f} - {PSNR.max():.2f} dB")
    else:
        print("âŒ æ²¡æœ‰æˆåŠŸè¯„ä¼°çš„å›¾åƒ")


def main():
    parser = argparse.ArgumentParser(description='U-shape Transformer æ°´ä¸‹å›¾åƒå¢å¼ºæµ‹è¯•')
    parser.add_argument('--input_dir', type=str, default='./test/input/',
                        help='è¾“å…¥å›¾åƒç›®å½•')
    parser.add_argument('--output_dir', type=str, default='./test/output/',
                        help='è¾“å‡ºå›¾åƒç›®å½•')
    parser.add_argument('--gt_dir', type=str, default='./test/GT/',
                        help='çœŸå€¼å›¾åƒç›®å½•ï¼ˆç”¨äºè¯„ä¼°ï¼‰')
    parser.add_argument('--model_path', type=str, default='./saved_models/G/generator_795.pth',
                        help='æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--device', type=str, default='cuda',
                        choices=['cuda', 'cpu'], help='è®¡ç®—è®¾å¤‡')
    parser.add_argument('--evaluate', action='store_true',
                        help='æ˜¯å¦è¿›è¡Œç»“æœè¯„ä¼°')

    args = parser.parse_args()

    # è®¾ç½®ç¯å¢ƒ
    setup_environment()

    # æ£€æŸ¥è®¾å¤‡
    if args.device == 'cuda' and not torch.cuda.is_available():
        print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPU")
        args.device = 'cpu'

    print(f"ä½¿ç”¨è®¾å¤‡: {args.device}")

    try:
        # æµ‹è¯•å›¾åƒ
        test_images(args.input_dir, args.output_dir, args.model_path, args.device)

        # è¯„ä¼°ç»“æœï¼ˆå¦‚æœéœ€è¦ï¼‰
        if args.evaluate:
            evaluate_results(args.gt_dir, args.output_dir)

    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        return 1

    return 0


if __name__ == '__main__':
    import sys

    sys.exit(main())
